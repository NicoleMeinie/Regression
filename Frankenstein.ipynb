{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Frankenstein.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpA1AqsegDyJhC1oGMxOF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoleMeinie/Regression/blob/master/Frankenstein.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf2TqNZlewS3",
        "colab_type": "text"
      },
      "source": [
        "#Sendy Logistics Challenge\n",
        "Logistics is fundamental to the success of a business.\n",
        "\n",
        "It is reported that in Africa, logistics add an average of 320% to a manufactured good’s cost. Sendy is a logistics platform servicing East Africa and aims to help businesses and enterprises grow through efficient and affordable logistics.\n",
        "\n",
        "Sendy is trying to predict accurate arrival times that will assist businesses in improving logistic operations and communicate accurate times to customers awaiting deliveries. Data is key in this endeavour and this project aims to use the given data to build a model to make these arrival time predictions. practical solutions for Africa’s dynamic transportation needs.\n",
        "\n",
        "The training dataset provided here is a subset of over 20,000 orders and only includes direct orders (i.e. Sendy “express” orders) with bikes in Nairobi. All data in this subset have been fully anonymized while preserving the distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrtNnaomfH52",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITiaYdhrezBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "%matplotlib inline\n",
        "\n",
        "# avoid pd warnings \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# should these be here or in the body of the code? - PEP8: They should be here. We'll collect them as we go along\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Gv51KHfaGz",
        "colab_type": "text"
      },
      "source": [
        "Three .csv files were provided: \"Train.csv\", \"Test.csv\" & \"Riders.csv\". Let's import these datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9wDsYg5fa41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import each csv file\n",
        "test_raw = pd.read_csv('Test.csv')\n",
        "train_raw = pd.read_csv('Train.csv')\n",
        "riders_raw = pd.read_csv('Riders.csv')\n",
        "Sub = pd.read_csv('SampleSubmission.csv')\n",
        "\n",
        "# Join riders to test & train data and initialise working dataframes\n",
        "Train = train_raw.merge(riders_raw, how=\"left\", on = \"Rider Id\") \n",
        "Test = test_raw.merge(riders_raw, how=\"left\", on = \"Rider Id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UFMf4vtfpX8",
        "colab_type": "text"
      },
      "source": [
        "Great! Let's build a model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjc7wcggfsHw",
        "colab_type": "text"
      },
      "source": [
        "#Exploratory Data Analysis\n",
        "Hold on! Exploratory Data Analysis is vital in determining our data structure; potential patterns & relationships between the variables in the dataset and ascertaining whether our dataset is in the best format for processing by the model we'll eventually be building. We've divided EDA into the following sections: Completeness, Data Types & Initial Variable Selection & Visualisation. Once we have 'the lay of the land' we'll move on to Preprocessing the datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8oR31L2gEYc",
        "colab_type": "text"
      },
      "source": [
        "##Completeness of the Data\n",
        "\n",
        "Quality of a dataset is dependent on completeness. Let's investigate which variables have those pesky null values and figure out a way forward to handle them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTkt_cyPhzhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_raw.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMyo4_uUfqQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_raw.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrYxZZxgh6kT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_raw.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuDMldXDkLci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_raw.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9cS-rApgUIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_raw.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0c6Wk0AiRJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.raw.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU_Etmc-kRPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "riders.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maOsbPuJgbEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "riders_raw.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aULixGk0ggFd",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "*  Both the train & test data sets have missing values for the 'Temperature' & 'Precipitation' columns. The values for the train data should be imputed using an appropriate method after the Train-Validation Split. Approximately 20% of the Temperature values are missing in both the Test & Train data sets. Replacing the NaN with the average would therefore be a reasonable assumption. Approximately 97% of the Precipitation values are missing. Imputation of the NaN values could be achieved either via assuming zero precipitation for those Order times, or imputation by mode.\n",
        "\n",
        "*  As the data has already been split into training & test sets we can go ahead and imput the values for each set. It's best practice to impute values after the split to ensure a fair test of the model evetually built.\n",
        "\n",
        "*  The riders.csv file has no missing values. Phew!\n",
        "\n",
        "*  Side Note: The column names for the test and train data could do with some formatting to get rid of spaces between strings, but perhaps we'll leave this as is to match the submission file format.\n",
        "\n",
        "*  The train data set has four additional columns centred arround the arrival time of the order: 'Arrival at Destination - Day of Month', 'Arrival at Destination - Weekday (Mo = 1)', 'Arrival at Destination - Time', 'Time from Pickup to Arrival'. Other than that the columns are identical. This is expected as if we had these columns present in the Test set, we wouldnt have a response variable to predict!\n",
        "\n",
        "*  It appears that the riders data could be joined with both the train and test data sets on the column 'Rider Id'. It is anticipated that some variables in this data set such as 'AverageRating' could be influential in predicting the response variable. What's that you say...? \"all this does is increase the No. of variables in both sets!\"... Yes, but there are definitely some variables that can be removed...\n",
        "\n",
        "*  Summary - impute missing temperature and precipitation values. Join riders to both test & train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljs3Ac4xtKnR",
        "colab_type": "text"
      },
      "source": [
        "##Distribution of the feature and response variables\n",
        "A histogram of delivery times as well as the outlier threshold will be plotted to viuslize the distribution of the delivery times (response/target variable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqdoXWa5tOtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating the outlier threshold \n",
        "mu = Train['Time from Pickup to Arrival'].mean()\n",
        "sd = Train['Time from Pickup to Arrival'].std()\n",
        "li = mu + 3*sd\n",
        "\n",
        "# creating the histogram - distribution of delivery times in seconds\n",
        "sns.set()\n",
        "_ = plt.figure(figsize = (10,5))\n",
        "_ = plt.hist(Train['Time from Pickup to Arrival'], bins = 70, color = 'blue')\n",
        "_ = plt.title('Delivery time distribution')\n",
        "_ = plt.xlabel('Delivery Time (seconds)')\n",
        "_ = plt.ylabel('Number of orders')\n",
        "_ = plt.axvline(li, color = 'gray', linestyle = 'dashed', linewidth = 1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcO-sI51tU5U",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "*   From the plot above it’s clear that the delivery times are possitively skewed, with the majority of orders being delivered in about 16 minutes \n",
        "\n",
        "*   There are orders with a delivery time of 1 second. These could be data points that weren't recorded properly. In practice these rows should be excluded when training the model.\n",
        "\n",
        "* The grey dotted line above indicates the threshold for existance of outliers (measured by the presence of values 3 standard deviation away from the mean.) A small portion of the delivery times recorded with times > 4500 seconds can be considered outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-6H-3cIt2l9",
        "colab_type": "text"
      },
      "source": [
        "## Distribution plots for all the features in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6wzwUKAt8rK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a histogram for all the variables in the dataset to visulize the distribution of each feature\n",
        "sns.set()\n",
        "Train.hist(bins = 60, figsize = (20,15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7iyY85Et-ZD",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "\n",
        "*   Majority of the orders are placed using platform 3 and only a tiny portion using platform 4\n",
        "*   Weekends are not as busy compared to weekdays \n",
        "* Most orders are delivered within a 10km radius\n",
        "* Orders are spread out almost evenly across the day of the month - no obvious popular day\n",
        "* Most Temperatures fall between 20 and 27 degrees celcius\n",
        "* The average driver rating is between 13 and 15 with vary little varience \n",
        "* A large portion of riders have no or very few ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM-j8zoFuZUi",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the relationship between delivery time and a few features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObBUHeDWufcu",
        "colab_type": "text"
      },
      "source": [
        "### Day of the week\n",
        "\n",
        "Next the relationship between the day of the week that orders are placed and the delivery times is visualized using a violin plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLkU2Mh3u1sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set()\n",
        "_ = plt.figure(figsize = (10,5))\n",
        "_ = sns.violinplot(x = Train['Placement - Weekday (Mo = 1)'], y = Train['Time from Pickup to Arrival'], data = Train )\n",
        "_ = plt.title('Delivery time vs Day of the week')\n",
        "_ = plt.xlabel('Day of the week')\n",
        "_ = plt.ylabel('Delivery Time (seconds)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsdwr-vxuys7",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        " \n",
        "\n",
        "*   Delivery times during the week have the same spread from monday to friday with slight differences in the extremity of outliers. \n",
        "\n",
        "* The delivery times during weekends have less variability and less extreme outliers. This could possibly be due to drivers experiencing less traffic over weekends "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51wXuafNx380",
        "colab_type": "text"
      },
      "source": [
        "### Type of client serviced\n",
        "Sendy handles deliveries for businesses and personal clients. Does the type of client serviced have an effect on the delivery time?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfDizsNyyqVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set()\n",
        "_ = plt.figure(figsize = (10,5))\n",
        "_ = sns.boxplot(x = Train['Personal or Business'], y = Train['Time from Pickup to Arrival'], data = Train )\n",
        "_ = plt.title('Delivery time vs type of client')\n",
        "_ = plt.xlabel('Platform')\n",
        "_ = plt.ylabel('Delivery Time in seconds')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E87sDCTNy_J6",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "*  There is almost no difference in the distibution of delivery times for personal clients compared to businesses with the exception of a few outliers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4-sHUOS1tIg",
        "colab_type": "text"
      },
      "source": [
        "### Platform used to place orders\n",
        "Users can place orders using 4 different platforms. Is there a relationship between the type of platform used to place an order and the delievry time?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mmoh2wpsvR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set()\n",
        "_ = plt.figure(figsize = (10,5))\n",
        "_ = sns.boxplot(x = Train['Platform Type'], y = Train['Time from Pickup to Arrival'], data = Train )\n",
        "_ = plt.title('Delivery time vs Platform type')\n",
        "_ = plt.xlabel('Platform')\n",
        "_ = plt.ylabel('Delivery Time in seconds')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XCtuseg2Wzu",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "*  The delivery times for platform types 1 to 3 are similar, although more outliers are observed when orders are placed using platform 3.\n",
        "\n",
        "*  Platform 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFDaLdNb3ioK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}